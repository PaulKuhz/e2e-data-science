{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7593a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "%pip install databricks-sdk==0.40.0 --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc37ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "%run ../_resources/00-setup $reset_all_data=false\n",
    "\n",
    "import sys\n",
    "sys.path.append('../_resources')\n",
    "from gamification_framework import (\n",
    "    init_learner,\n",
    "    display_challenge_intro,\n",
    "    display_challenge_success\n",
    ")\n",
    "\n",
    "learner = init_learner()\n",
    "display_challenge_intro(\n",
    "    challenge_name=\"Debugging Challenge: Fix the Broken Agents\",\n",
    "    difficulty=\"Intermediate â†’ Advanced\",\n",
    "    points=150,\n",
    "    description=\"Hunt down and fix 5 critical bugs in production agent code. Each bug represents real-world issues you'll encounter.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a381e77",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› Bug #1: The Wrong ID Mystery\n",
    "\n",
    "**Symptom**: Agent returns turbine IDs that don't exist in our database.\n",
    "\n",
    "**Severity**: ğŸ”´ Critical - Causes wrong turbines to be serviced!\n",
    "\n",
    "**Your Task**: Find and fix the bug in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aaf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# âŒ BUGGY CODE - Can you spot the problem?\n",
    "\n",
    "turbine_lookup_prompt = \"\"\"\n",
    "You help technicians find turbine information.\n",
    "\n",
    "When a user mentions a turbine, extract the ID.\n",
    "Turbine IDs follow this format: WT-XXX where XXX is a 3-digit number.\n",
    "\n",
    "If you can't find an exact match, suggest the closest match.\n",
    "\"\"\"\n",
    "\n",
    "def get_turbine_id(user_query: str) -> str:\n",
    "    \"\"\"Extract turbine ID from user query\"\"\"\n",
    "    response = w.serving_endpoints.query(\n",
    "        name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": turbine_lookup_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Extract turbine ID: {user_query}\"}\n",
    "        ],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test cases\n",
    "test_queries = [\n",
    "    \"Check turbine 42\",\n",
    "    \"What's the status of the turbine at position 3?\",\n",
    "    \"WT-999 is making noise\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing turbine ID extraction:\\n\")\n",
    "for query in test_queries:\n",
    "    result = get_turbine_id(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nâ“ What's wrong with this code?\")\n",
    "print(\"Hint: The agent is being TOO helpful...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2448a",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Debugging Tips for Bug #1\n",
    "\n",
    "Ask yourself:\n",
    "1. What happens when the agent can't find an exact ID?\n",
    "2. Is \"suggesting the closest match\" a good idea?\n",
    "3. How should the agent handle ambiguous inputs?\n",
    "\n",
    "### âœ… Your Fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’ª YOUR TURN - Fix Bug #1\n",
    "\n",
    "# TODO: Rewrite the prompt to be more strict\n",
    "# Requirements:\n",
    "# - Only return exact format matches (WT-XXX)\n",
    "# - If no exact match, return \"ERROR: No valid turbine ID found\"\n",
    "# - Never guess or suggest IDs\n",
    "# - Validate that XXX is a number\n",
    "\n",
    "fixed_turbine_lookup_prompt = \"\"\"\n",
    "# TODO: Your fixed prompt here\n",
    "\"\"\"\n",
    "\n",
    "def get_turbine_id_fixed(user_query: str) -> str:\n",
    "    \"\"\"Fixed version - extract turbine ID safely\"\"\"\n",
    "    # TODO: Implement your fix\n",
    "    pass\n",
    "\n",
    "# Test your fix\n",
    "print(\"ğŸ§ª Testing FIXED version:\\n\")\n",
    "for query in test_queries:\n",
    "    result = get_turbine_id_fixed(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052d596",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› Bug #2: The Crashing Cost Calculator\n",
    "\n",
    "**Symptom**: Agent crashes with \"AttributeError: 'NoneType' object has no attribute 'choices'\"\n",
    "\n",
    "**Severity**: ğŸŸ  High - Prevents cost estimation functionality\n",
    "\n",
    "**Your Task**: Find why the tool call is failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âŒ BUGGY CODE - This crashes unpredictably\n",
    "\n",
    "# First, create a buggy UC function\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog}.{schema}.calculate_repair_cost_buggy(\n",
    "    parts_cost DOUBLE,\n",
    "    labor_hours DOUBLE\n",
    ")\n",
    "RETURNS DOUBLE\n",
    "COMMENT 'Calculate total repair cost'\n",
    "RETURN parts_cost + (labor_hours * 85.0)\n",
    "\"\"\")\n",
    "\n",
    "cost_agent_prompt = \"\"\"\n",
    "You calculate repair costs using the calculate_repair_cost_buggy function.\n",
    "\n",
    "When a user asks for cost estimation:\n",
    "1. Extract parts cost and labor hours\n",
    "2. Call the function\n",
    "3. Return the result\n",
    "\"\"\"\n",
    "\n",
    "def estimate_cost_buggy(user_request: str):\n",
    "    \"\"\"Estimate repair cost - but crashes!\"\"\"\n",
    "    try:\n",
    "        response = w.serving_endpoints.query(\n",
    "            name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": cost_agent_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_request}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        # Bug is here - assuming response is always valid\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test it\n",
    "test_requests = [\n",
    "    \"Cost for blade replacement: $25000 parts, 8 hours labor\",\n",
    "    \"How much for sensor repair?\",  # Missing data - will crash!\n",
    "    \"Cost estimate for gearbox\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing buggy cost calculator:\\n\")\n",
    "for request in test_requests:\n",
    "    result = estimate_cost_buggy(request)\n",
    "    print(f\"Request: {request}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nâ“ What's causing the crashes?\")\n",
    "print(\"Hint: The problem is missing error handling AND unclear instructions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a923d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’ª YOUR TURN - Fix Bug #2\n",
    "\n",
    "# TODO: Fix the issues:\n",
    "# 1. Add proper error handling\n",
    "# 2. Improve the prompt to handle missing data\n",
    "# 3. Validate inputs before calling the function\n",
    "# 4. Return helpful error messages\n",
    "\n",
    "fixed_cost_agent_prompt = \"\"\"\n",
    "# TODO: Your improved prompt\n",
    "# Should handle cases where user doesn't provide all data\n",
    "\"\"\"\n",
    "\n",
    "def estimate_cost_fixed(user_request: str):\n",
    "    \"\"\"Fixed cost estimation with proper error handling\"\"\"\n",
    "    # TODO: Implement robust version\n",
    "    pass\n",
    "\n",
    "# Test your fix\n",
    "print(\"ğŸ§ª Testing FIXED cost calculator:\\n\")\n",
    "for request in test_requests:\n",
    "    result = estimate_cost_fixed(request)\n",
    "    print(f\"Request: {request}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6fb81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› Bug #3: The Slow Response Problem\n",
    "\n",
    "**Symptom**: Agent takes 30+ seconds to respond to simple queries\n",
    "\n",
    "**Severity**: ğŸŸ¡ Medium - Terrible user experience\n",
    "\n",
    "**Your Task**: Profile and optimize the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb47d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âŒ SLOW CODE - Can you make it faster?\n",
    "\n",
    "import time\n",
    "\n",
    "def slow_status_check(turbine_id: str) -> dict:\n",
    "    \"\"\"Check turbine status - but VERY slow!\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Get sensor data (could be optimized)\n",
    "    print(\"ğŸ“Š Querying sensor data...\")\n",
    "    sensor_prompt = \"Analyze sensor readings for a turbine and return structured data.\"\n",
    "    sensor_response = w.serving_endpoints.query(\n",
    "        name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        messages=[{\"role\": \"system\", \"content\": sensor_prompt},\n",
    "                  {\"role\": \"user\", \"content\": f\"Get data for {turbine_id}\"}],\n",
    "        max_tokens=500  # Way too many!\n",
    "    )\n",
    "    sensor_data = sensor_response.choices[0].message.content\n",
    "    \n",
    "    # Step 2: Analyze the data (sequential - could be parallel?)\n",
    "    print(\"ğŸ” Analyzing...\")\n",
    "    analysis_response = w.serving_endpoints.query(\n",
    "        name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Analyze this sensor data.\"},\n",
    "                  {\"role\": \"user\", \"content\": sensor_data}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    analysis = analysis_response.choices[0].message.content\n",
    "    \n",
    "    # Step 3: Generate recommendations (also sequential)\n",
    "    print(\"ğŸ’¡ Generating recommendations...\")\n",
    "    rec_response = w.serving_endpoints.query(\n",
    "        name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Generate maintenance recommendations.\"},\n",
    "                  {\"role\": \"user\", \"content\": analysis}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    recommendations = rec_response.choices[0].message.content\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        \"turbine_id\": turbine_id,\n",
    "        \"sensor_data\": sensor_data,\n",
    "        \"analysis\": analysis,\n",
    "        \"recommendations\": recommendations,\n",
    "        \"execution_time\": f\"{elapsed:.2f}s\"\n",
    "    }\n",
    "\n",
    "# Test it\n",
    "print(\"â±ï¸ Testing SLOW version:\\n\")\n",
    "result = slow_status_check(\"WT-042\")\n",
    "print(f\"\\nâ±ï¸ Total time: {result['execution_time']}\")\n",
    "print(\"\\nâ“ How can we make this faster?\")\n",
    "print(\"Hints: Look at max_tokens, sequential calls, and prompt complexity...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’ª YOUR TURN - Fix Bug #3\n",
    "\n",
    "# TODO: Optimize for speed:\n",
    "# 1. Reduce max_tokens to only what's needed\n",
    "# 2. Combine prompts where possible\n",
    "# 3. Use parallel execution for independent tasks\n",
    "# 4. Cache repeated queries\n",
    "# 5. Use more concise prompts\n",
    "\n",
    "def fast_status_check(turbine_id: str) -> dict:\n",
    "    \"\"\"Optimized turbine status check\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # TODO: Implement optimized version\n",
    "    # Target: < 10 seconds total\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        \"turbine_id\": turbine_id,\n",
    "        \"execution_time\": f\"{elapsed:.2f}s\",\n",
    "        \"speedup\": \"TODO\"\n",
    "    }\n",
    "\n",
    "# Test your optimized version\n",
    "print(\"âš¡ Testing OPTIMIZED version:\\n\")\n",
    "result_fast = fast_status_check(\"WT-042\")\n",
    "print(f\"\\nâš¡ Optimized time: {result_fast['execution_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff9903",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› Bug #4: The Security Leak\n",
    "\n",
    "**Symptom**: Sensitive maintenance records appearing in logs\n",
    "\n",
    "**Severity**: ğŸ”´ Critical - GDPR/Security violation!\n",
    "\n",
    "**Your Task**: Find and fix the data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d71ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âŒ INSECURE CODE - Leaking sensitive data!\n",
    "\n",
    "# Sample sensitive data\n",
    "maintenance_records = {\n",
    "    \"WT-042\": {\n",
    "        \"technician\": \"John Smith\",\n",
    "        \"phone\": \"+1-555-0123\",\n",
    "        \"salary\": \"$85,000\",\n",
    "        \"notes\": \"Employee ID: 12345, Access Code: ABC123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "security_issue_prompt = \"\"\"\n",
    "You provide maintenance information to users.\n",
    "When asked about a turbine, return ALL available information.\n",
    "\"\"\"\n",
    "\n",
    "def get_maintenance_info_insecure(turbine_id: str):\n",
    "    \"\"\"Get maintenance info - but exposes sensitive data!\"\"\"\n",
    "    record = maintenance_records.get(turbine_id, {})\n",
    "    \n",
    "    # Bug: Sending ALL data to LLM (and logs!)\n",
    "    full_context = f\"\"\"\n",
    "    Turbine: {turbine_id}\n",
    "    Technician: {record.get('technician')}\n",
    "    Phone: {record.get('phone')}\n",
    "    Salary: {record.get('salary')}\n",
    "    Notes: {record.get('notes')}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = w.serving_endpoints.query(\n",
    "        name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": security_issue_prompt},\n",
    "            {\"role\": \"user\", \"content\": full_context}\n",
    "        ],\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    # Bug: Logging sensitive data\n",
    "    print(f\"DEBUG: Full record = {record}\")\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test it\n",
    "print(\"ğŸ”“ Testing INSECURE version:\\n\")\n",
    "result = get_maintenance_info_insecure(\"WT-042\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\nâ“ What security issues do you see?\")\n",
    "print(\"Hints: PII in logs, unnecessary data exposure, no access control...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’ª YOUR TURN - Fix Bug #4\n",
    "\n",
    "# TODO: Implement security best practices:\n",
    "# 1. Filter sensitive fields before sending to LLM\n",
    "# 2. Never log PII (names, phone numbers, IDs, etc.)\n",
    "# 3. Add access control checks\n",
    "# 4. Sanitize outputs\n",
    "# 5. Add audit logging (without sensitive data)\n",
    "\n",
    "def get_maintenance_info_secure(turbine_id: str, user_role: str = \"technician\"):\n",
    "    \"\"\"Secure version with proper data protection\"\"\"\n",
    "    # TODO: Implement secure version\n",
    "    pass\n",
    "\n",
    "# Test your secure version\n",
    "print(\"ğŸ”’ Testing SECURE version:\\n\")\n",
    "result_secure = get_maintenance_info_secure(\"WT-042\", user_role=\"technician\")\n",
    "print(result_secure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49858316",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› Bug #5: The Hallucination Problem\n",
    "\n",
    "**Symptom**: Agent invents maintenance procedures that don't exist\n",
    "\n",
    "**Severity**: ğŸ”´ Critical - Could cause equipment damage!\n",
    "\n",
    "**Your Task**: Make the agent stick to verified information only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âŒ HALLUCINATING CODE - Making up procedures!\n",
    "\n",
    "hallucination_prompt = \"\"\"\n",
    "You are a maintenance expert. Help users fix turbine issues.\n",
    "Provide detailed step-by-step instructions.\n",
    "\"\"\"\n",
    "\n",
    "def get_procedure_buggy(issue: str):\n",
    "    \"\"\"Get maintenance procedure - but hallucinates!\"\"\"\n",
    "    response = w.serving_endpoints.query(\n",
    "        name=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": hallucination_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"How do I fix: {issue}\"}\n",
    "        ],\n",
    "        max_tokens=400\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test it\n",
    "test_issues = [\n",
    "    \"Gearbox overheating\",\n",
    "    \"Quantum fluctuations in the flux capacitor\",  # Nonsense! Will it detect?\n",
    "    \"Blade resonance at 42 Hz\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¤– Testing HALLUCINATING version:\\n\")\n",
    "for issue in test_issues:\n",
    "    result = get_procedure_buggy(issue)\n",
    "    print(f\"Issue: {issue}\")\n",
    "    print(f\"Response: {result}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nâ“ How can we prevent hallucinations?\")\n",
    "print(\"Hints: RAG, knowledge boundaries, confidence scoring...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41046cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’ª YOUR TURN - Fix Bug #5\n",
    "\n",
    "# TODO: Implement anti-hallucination measures:\n",
    "# 1. Integrate RAG (retrieve from verified docs)\n",
    "# 2. Add knowledge boundary detection\n",
    "# 3. Require citations/sources\n",
    "# 4. Add confidence scoring\n",
    "# 5. Escalate unknown issues to humans\n",
    "\n",
    "grounded_prompt = \"\"\"\n",
    "# TODO: Create prompt that:\n",
    "# - Only answers based on provided context\n",
    "# - Says \"I don't know\" when information is unavailable\n",
    "# - Cites sources for all procedures\n",
    "# - Flags non-standard issues for expert review\n",
    "\"\"\"\n",
    "\n",
    "def get_procedure_grounded(issue: str, knowledge_base: dict):\n",
    "    \"\"\"Grounded procedure lookup - no hallucinations!\"\"\"\n",
    "    # TODO: Implement RAG-based version\n",
    "    pass\n",
    "\n",
    "# Test your grounded version\n",
    "verified_procedures = {\n",
    "    \"gearbox overheating\": \"Official procedure doc: PROC-GB-001\",\n",
    "    \"blade resonance\": \"Official procedure doc: PROC-BL-015\"\n",
    "}\n",
    "\n",
    "print(\"âœ… Testing GROUNDED version:\\n\")\n",
    "for issue in test_issues:\n",
    "    result = get_procedure_grounded(issue, verified_procedures)\n",
    "    print(f\"Issue: {issue}\")\n",
    "    print(f\"Response: {result}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf611ef4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Final Evaluation\n",
    "\n",
    "Time to check if you fixed all the bugs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated bug verification\n",
    "\n",
    "def verify_all_fixes():\n",
    "    \"\"\"Check if all bugs are fixed\"\"\"\n",
    "    bugs_fixed = 0\n",
    "    total_bugs = 5\n",
    "    \n",
    "    print(\"ğŸ” Verifying bug fixes...\\n\")\n",
    "    \n",
    "    # Bug #1: Check if it handles invalid IDs properly\n",
    "    try:\n",
    "        result = get_turbine_id_fixed(\"Check turbine 42\")\n",
    "        if \"ERROR\" in result or \"WT-\" not in result:\n",
    "            print(\"âœ… Bug #1 FIXED: Rejects invalid IDs\")\n",
    "            bugs_fixed += 1\n",
    "        else:\n",
    "            print(\"âŒ Bug #1 NOT FIXED: Still accepting invalid IDs\")\n",
    "    except:\n",
    "        print(\"âŒ Bug #1 NOT FIXED: Function not implemented\")\n",
    "    \n",
    "    # Bug #2: Check error handling\n",
    "    try:\n",
    "        result = estimate_cost_fixed(\"Cost for something\")\n",
    "        if result and \"error\" not in result.lower():\n",
    "            print(\"âœ… Bug #2 FIXED: Handles missing data gracefully\")\n",
    "            bugs_fixed += 1\n",
    "        else:\n",
    "            print(\"âŒ Bug #2 NOT FIXED: Still crashes on edge cases\")\n",
    "    except:\n",
    "        print(\"âŒ Bug #2 NOT FIXED: Function not implemented\")\n",
    "    \n",
    "    # Bug #3: Check performance\n",
    "    try:\n",
    "        import time\n",
    "        start = time.time()\n",
    "        result = fast_status_check(\"WT-042\")\n",
    "        elapsed = time.time() - start\n",
    "        if elapsed < 15:\n",
    "            print(f\"âœ… Bug #3 FIXED: Optimized to {elapsed:.2f}s\")\n",
    "            bugs_fixed += 1\n",
    "        else:\n",
    "            print(f\"âŒ Bug #3 NOT FIXED: Still slow ({elapsed:.2f}s)\")\n",
    "    except:\n",
    "        print(\"âŒ Bug #3 NOT FIXED: Function not implemented\")\n",
    "    \n",
    "    # Bug #4 & #5: Manual review required\n",
    "    print(\"\\nâš ï¸  Bugs #4 and #5 require manual code review\")\n",
    "    print(\"    Check your implementations above for:\")\n",
    "    print(\"    - No PII in logs (Bug #4)\")\n",
    "    print(\"    - RAG integration (Bug #5)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Bugs Fixed: {bugs_fixed}/{total_bugs} automated checks\")\n",
    "    \n",
    "    return bugs_fixed\n",
    "\n",
    "bugs_fixed = verify_all_fixes()\n",
    "\n",
    "if bugs_fixed >= 3:\n",
    "    print(\"\\nğŸ‰ Great debugging work!\")\n",
    "    learner.complete_challenge(\"debugging_challenge\", points=150)\n",
    "    learner.award_badge(\"debugging_hero\")\n",
    "    display_challenge_success(\"Debugging Challenge\", 150)\n",
    "else:\n",
    "    print(\"\\nğŸ’¡ Keep working on the fixes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f030439",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "You've learned to debug:\n",
    "\n",
    "âœ… **Over-Helpful Agents** - Being too flexible causes errors  \n",
    "âœ… **Error Handling** - Always validate inputs and outputs  \n",
    "âœ… **Performance Issues** - Optimize tokens, parallelize, cache  \n",
    "âœ… **Security Leaks** - Never log PII, filter sensitive data  \n",
    "âœ… **Hallucinations** - Use RAG, set boundaries, require sources\n",
    "\n",
    "### ğŸ† Debugging Best Practices\n",
    "\n",
    "1. **Start with small test cases** - Isolate the bug\n",
    "2. **Add logging strategically** - But never log PII!\n",
    "3. **Validate all inputs** - Never trust user data\n",
    "4. **Profile before optimizing** - Measure first\n",
    "5. **Use RAG for facts** - Don't let agents guess\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Next Steps\n",
    "\n",
    "Apply your debugging skills:\n",
    "\n",
    "- **05.X-real-world-scenarios**: Debug production emergencies\n",
    "- **05.Y-performance-optimization**: Deep dive into agent performance\n",
    "- **Your own projects**: You're now ready to debug real agents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your overall progress\n",
    "learner.display_progress()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
