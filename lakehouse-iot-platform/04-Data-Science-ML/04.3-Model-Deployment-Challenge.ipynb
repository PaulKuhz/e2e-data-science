{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a7e08f",
   "metadata": {},
   "source": [
    "# ğŸš€ Model Deployment Challenge\n",
    "\n",
    "**Welcome to the MLOps Challenge!** You've trained and optimized your model in **04.2**. Now it's time to **deploy it to production** and make it available for real-world predictions!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Your Mission\n",
    "\n",
    "Deploy your ML model using **two production strategies**:\n",
    "\n",
    "1. **Batch Inference (Spark UDF)** - Process thousands of turbines daily\n",
    "2. **Real-Time API (REST Endpoint)** - Instant predictions for live sensor data\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š The Challenge\n",
    "\n",
    "**Scenario:** Your energy company needs predictions in two ways:\n",
    "\n",
    "**ğŸ”„ Batch Processing:**\n",
    "- Run daily analysis on all 10,000 turbines\n",
    "- Generate maintenance reports\n",
    "- Store predictions in data warehouse\n",
    "- **Use Case:** Overnight batch jobs, historical analysis\n",
    "\n",
    "**âš¡ Real-Time API:**\n",
    "- IoT sensors send live data\n",
    "- Instant prediction (< 1 second)\n",
    "- Trigger alerts for critical failures\n",
    "- **Use Case:** Mobile apps, monitoring dashboards, alerting systems\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† Challenge Levels\n",
    "\n",
    "### **Level 1: Batch Inference with Spark UDF (30 min)**\n",
    "- Load registered model from Unity Catalog\n",
    "- Create Spark User-Defined Function (UDF)\n",
    "- Apply predictions to entire dataset\n",
    "- Save results as table\n",
    "\n",
    "### **Level 2: REST API Deployment (45 min)**\n",
    "- Create Model Serving Endpoint\n",
    "- Configure scale-to-zero for cost optimization\n",
    "- Wait for endpoint deployment (~15 min)\n",
    "- Test API with sample data\n",
    "\n",
    "### **Level 3: Advanced Testing & Integration (30 min)**\n",
    "- Build robust API client function\n",
    "- Test different input formats\n",
    "- Handle errors gracefully\n",
    "- Compare batch vs real-time performance\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ What You'll Learn\n",
    "\n",
    "âœ… **Spark UDFs** - Integrate ML into SQL/DataFrames  \n",
    "âœ… **Model Serving** - Production-grade REST APIs  \n",
    "âœ… **Scale-to-Zero** - Cost-effective deployment  \n",
    "âœ… **Batch vs Real-Time** - Choose the right strategy  \n",
    "âœ… **API Testing** - POST requests and error handling  \n",
    "âœ… **MLOps Best Practices** - Versioning, monitoring, lineage  \n",
    "\n",
    "---\n",
    "\n",
    "Let's deploy! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851035d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¦ Setup: Install Libraries\n",
    "\n",
    "**What you need to do:**\n",
    "Install required packages for model deployment.\n",
    "\n",
    "**ğŸ’¡ Note:** After installation, Python kernel will restart automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22241311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL - No changes needed\n",
    "%pip install --quiet databricks-sdk==0.40.0 mlflow==2.22.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL - No changes needed\n",
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d922d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¥ Task 1: Import Libraries & Configure MLflow\n",
    "\n",
    "**What you need to do:**\n",
    "1. Import necessary libraries for deployment\n",
    "2. Configure MLflow to use Unity Catalog\n",
    "\n",
    "**Libraries you'll need:**\n",
    "- **mlflow:** Model loading and serving\n",
    "- **mlflow.deployments:** Deployment client for endpoints\n",
    "- **requests:** HTTP API calls\n",
    "- **json:** JSON data formatting\n",
    "- **pandas & numpy:** Data manipulation\n",
    "\n",
    "**ğŸ’¡ Hint:** Same setup as 04.2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d80fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Import libraries\n",
    "# Hint: import numpy as np\n",
    "#       import pandas as pd\n",
    "#       import mlflow\n",
    "#       from mlflow.models import infer_signature\n",
    "#       from mlflow import MlflowClient\n",
    "#       from mlflow.deployments import get_deploy_client\n",
    "#       import os\n",
    "#       import requests\n",
    "#       import json\n",
    "#       import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Configure MLflow to use Unity Catalog\n",
    "# Hint: mlflow.set_registry_uri('databricks-uc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b663d9",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- All libraries imported without errors\n",
    "- MLflow configured for Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b3f1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ LEVEL 1: Batch Inference with Spark UDF (30 min)\n",
    "\n",
    "**Goal:** Deploy model for batch predictions on large datasets\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Background: What is a Spark UDF?\n",
    "\n",
    "**User-Defined Function (UDF):** Custom function that can be used in Spark SQL and DataFrames\n",
    "\n",
    "**Why use UDFs for ML?**\n",
    "- âœ… Process millions of rows in parallel\n",
    "- âœ… Use SQL for predictions (accessible to analysts)\n",
    "- âœ… Seamlessly integrate ML into data pipelines\n",
    "- âœ… Results saved as tables for downstream use\n",
    "\n",
    "**How it works:**\n",
    "```python\n",
    "# 1. Load model as Spark UDF\n",
    "predict_udf = mlflow.pyfunc.spark_udf(spark, model_uri)\n",
    "\n",
    "# 2. Apply to DataFrame\n",
    "df.withColumn('prediction', predict_udf(col1, col2, ...))\n",
    "\n",
    "# 3. Use in SQL\n",
    "SELECT predict_udf(col1, col2) FROM table\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51845c70",
   "metadata": {},
   "source": [
    "## ğŸ“ Task 2: Load Model from Unity Catalog\n",
    "\n",
    "**What you need to do:**\n",
    "1. Define model name (same as in 04.2)\n",
    "2. Create Spark UDF from registered model\n",
    "3. Register UDF for use in SQL queries\n",
    "\n",
    "**ğŸ’¡ Important:**\n",
    "- Use `@prod` alias to load production model\n",
    "- `env_manager='virtualenv'` ensures consistent environment\n",
    "- â±ï¸ **First run takes 15+ minutes** to build virtual environment\n",
    "\n",
    "**Model URI format:** `models:/{catalog}.{db}.{model_name}@prod`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc55789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Define model name\n",
    "# Hint: model_name = \"turbine_maintenance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48897b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Create Spark UDF from model\n",
    "# This loads the model in a virtual environment (can take 15+ minutes!)\n",
    "\n",
    "# Hint:\n",
    "# predict_maintenance = mlflow.pyfunc.spark_udf(\n",
    "#     spark, \n",
    "#     f\"models:/{catalog}.{db}.{model_name}@prod\",\n",
    "#     result_type=\"float\",  # Output type\n",
    "#     env_manager='virtualenv'\n",
    "# )\n",
    "\n",
    "print(\"â³ Building virtual environment... This may take 15+ minutes on first run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Register UDF for SQL use\n",
    "# This allows you to call predict_maintenance() in SQL queries\n",
    "\n",
    "# Hint: spark.udf.register(\"predict_maintenance\", predict_maintenance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312be0c",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- UDF created successfully (may take 15+ min)\n",
    "- UDF registered for SQL use\n",
    "- No errors during loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5a884",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Task 3: Inspect Model Input Schema\n",
    "\n",
    "**What you need to do:**\n",
    "1. Get list of input columns the model expects\n",
    "2. Display input schema\n",
    "3. Verify column names match your feature table\n",
    "\n",
    "**ğŸ’¡ Why?** Ensures you pass the correct features in the right order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd404523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Get input column names\n",
    "# Hint: columns = predict_maintenance.metadata.get_input_schema().input_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Display columns\n",
    "# Print the list to see what features the model expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb890573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Display full input schema\n",
    "# Hint: predict_maintenance.metadata.get_input_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2dca2",
   "metadata": {},
   "source": [
    "### ğŸ¤” Reflection Question:\n",
    "**What columns does the model expect?**\n",
    "```\n",
    "[Your answer: Should be 7 features - avg_energy, std_sensor_A through F]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433ac7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ Task 4: Apply UDF to DataFrame (Batch Predictions)\n",
    "\n",
    "**What you need to do:**\n",
    "1. Load `turbine_hourly_features` table\n",
    "2. Apply UDF to add prediction column\n",
    "3. Display results\n",
    "4. Save predictions as new table: `turbine_hourly_predictions`\n",
    "\n",
    "**ğŸ’¡ Structure:**\n",
    "```python\n",
    "df = spark.table('turbine_hourly_features')\n",
    "df_with_pred = df.withColumn('prediction', predict_maintenance(*columns))\n",
    "df_with_pred.write.mode('overwrite').saveAsTable('turbine_hourly_predictions')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b60afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Apply UDF to DataFrame\n",
    "\n",
    "# Step 1: Load feature table\n",
    "# Hint: spark.table('turbine_hourly_features')\n",
    "\n",
    "# Step 2: Add prediction column using UDF\n",
    "# Hint: .withColumn(\"predict_turbine_maintenance\", predict_maintenance(*columns))\n",
    "\n",
    "# Step 3: Display results\n",
    "# Hint: display(batch_pred_df)\n",
    "\n",
    "# Step 4: Save as table\n",
    "# Hint: batch_pred_df.write.mode(\"overwrite\").saveAsTable(\"turbine_hourly_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3d3cf",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- Predictions added as new column\n",
    "- Predictions are numeric (0, 1, 2 for different failure types)\n",
    "- Table `turbine_hourly_predictions` created successfully\n",
    "- All rows have predictions (no NULLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424e0c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Task 5: Use UDF in SQL Query\n",
    "\n",
    "**What you need to do:**\n",
    "Write a SQL query that:\n",
    "1. Uses the `predict_maintenance()` UDF\n",
    "2. Selects `turbine_id` and prediction\n",
    "3. Passes all required sensor features\n",
    "4. Limits to 10 rows\n",
    "\n",
    "**ğŸ’¡ This shows how analysts can use your ML model directly in SQL!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb715ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Write SQL query using UDF\n",
    "\n",
    "%sql\n",
    "-- Example structure:\n",
    "-- SELECT turbine_id, \n",
    "--        predict_maintenance(\n",
    "--            avg_energy, \n",
    "--            std_sensor_A, \n",
    "--            std_sensor_B, \n",
    "--            std_sensor_C, \n",
    "--            std_sensor_D, \n",
    "--            std_sensor_E, \n",
    "--            std_sensor_F\n",
    "--        ) as prediction \n",
    "-- FROM turbine_hourly_features\n",
    "-- LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7623b",
   "metadata": {},
   "source": [
    "### ğŸ¤” Reflection Questions:\n",
    "\n",
    "**1. What are the advantages of UDFs for batch inference?**\n",
    "```\n",
    "[Your answer: Think about scale, integration with existing pipelines, SQL accessibility]\n",
    "```\n",
    "\n",
    "**2. When would you use batch inference vs real-time?**\n",
    "```\n",
    "[Your answer: Consider latency requirements, data volume, use cases]\n",
    "```\n",
    "\n",
    "**3. How many turbines did you score? How long did it take?**\n",
    "```\n",
    "[Your answer: Check row count and execution time]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aec65de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸš€ LEVEL 2: REST API Deployment (45 min)\n",
    "\n",
    "**Goal:** Deploy model as a REST API endpoint for real-time predictions\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¡ Background: Why REST API Endpoints?\n",
    "\n",
    "**REST API Serving:** Model hosted as web service\n",
    "\n",
    "**Benefits:**\n",
    "- âš¡ **Real-time:** Sub-second predictions\n",
    "- ğŸŒ **Accessible:** Call from any application (mobile, web, IoT)\n",
    "- ğŸ”’ **Secure:** Token-based authentication\n",
    "- ğŸ’° **Cost-effective:** Scale-to-zero when idle\n",
    "\n",
    "**Use Cases:**\n",
    "- Mobile app for field technicians\n",
    "- Live monitoring dashboard\n",
    "- Alerting system for critical failures\n",
    "- Integration with external systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612e86d",
   "metadata": {},
   "source": [
    "## ğŸ”§ Task 6: Prepare Endpoint Configuration\n",
    "\n",
    "**What you need to do:**\n",
    "1. Display endpoint name (defined in setup)\n",
    "2. Initialize deployment client\n",
    "3. Check if endpoint already exists\n",
    "4. Delete existing endpoint if found (for clean deployment)\n",
    "\n",
    "**ğŸ’¡ Note:** `MODEL_SERVING_ENDPOINT_NAME` is set in the setup script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dca974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Display endpoint name\n",
    "# Hint: print(MODEL_SERVING_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Delete existing endpoint if it exists\n",
    "# This ensures a clean deployment\n",
    "\n",
    "# Hint:\n",
    "# client = get_deploy_client(\"databricks\")\n",
    "# \n",
    "# for endpoint in client.list_endpoints():\n",
    "#     if endpoint['name'] == MODEL_SERVING_ENDPOINT_NAME:\n",
    "#         print(f\"Deleting existing endpoint: {MODEL_SERVING_ENDPOINT_NAME}\")\n",
    "#         client.delete_endpoint(MODEL_SERVING_ENDPOINT_NAME)\n",
    "#         print(\"Endpoint deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3ccb7",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- Endpoint name displayed\n",
    "- Deployment client initialized\n",
    "- Old endpoint deleted (if existed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b2b27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ Task 7: Create Serving Endpoint\n",
    "\n",
    "**What you need to do:**\n",
    "1. Create endpoint configuration\n",
    "2. Deploy model from Unity Catalog\n",
    "3. Configure workload size and scale-to-zero\n",
    "4. Wait for endpoint to be ready (~15 minutes)\n",
    "\n",
    "**â±ï¸ Important:** Endpoint creation takes **15+ minutes** - be patient!\n",
    "\n",
    "**Configuration Options:**\n",
    "- `workload_size`: \"Small\" (sufficient for testing)\n",
    "- `scale_to_zero_enabled`: True (cost optimization)\n",
    "- `entity_version`: Get latest version from registry\n",
    "\n",
    "**ğŸ’¡ Scale-to-Zero:** Endpoint shuts down after 15 min of inactivity, restarts automatically on request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Create serving endpoint\n",
    "# This spins up a container to run the model for inference\n",
    "\n",
    "# Step 1: Initialize deployment client\n",
    "# client = get_deploy_client(\"databricks\")\n",
    "\n",
    "# Step 2: Create endpoint\n",
    "# try:\n",
    "#     endpoint = client.create_endpoint(\n",
    "#         name=MODEL_SERVING_ENDPOINT_NAME,\n",
    "#         config={\n",
    "#             \"served_entities\": [\n",
    "#                 {\n",
    "#                     \"name\": \"iot-maintenance-serving-endpoint\",\n",
    "#                     \"entity_name\": f\"{catalog}.{db}.{model_name}\",\n",
    "#                     \"entity_version\": get_last_model_version(f\"{catalog}.{db}.{model_name}\"),\n",
    "#                     \"workload_size\": \"Small\",\n",
    "#                     \"scale_to_zero_enabled\": True\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     )\n",
    "#     print(f\"âœ… Endpoint {MODEL_SERVING_ENDPOINT_NAME} creation started!\")\n",
    "# except Exception as e:\n",
    "#     if \"already exists\" in str(e):\n",
    "#         print(f\"Endpoint {MODEL_SERVING_ENDPOINT_NAME} already exists.\")\n",
    "#     else:\n",
    "#         raise e\n",
    "\n",
    "print(\"â³ Waiting for endpoint to be ready... (15+ minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a44ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Wait for endpoint to be ready\n",
    "# This checks status every 10 seconds until ready\n",
    "\n",
    "# Hint:\n",
    "# while client.get_endpoint(MODEL_SERVING_ENDPOINT_NAME)['state']['config_update'] == 'IN_PROGRESS':\n",
    "#     print(\"â³ Still deploying...\")\n",
    "#     time.sleep(10)\n",
    "# \n",
    "# if client.get_endpoint(MODEL_SERVING_ENDPOINT_NAME)['state']['ready'] != 'READY':\n",
    "#     print(f\"âŒ Endpoint {MODEL_SERVING_ENDPOINT_NAME} creation failed.\")\n",
    "# else:\n",
    "#     print(f\"âœ… Endpoint {MODEL_SERVING_ENDPOINT_NAME} is READY!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1bdcb",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- Endpoint creation started successfully\n",
    "- Status check loop running\n",
    "- Final status: READY\n",
    "- â±ï¸ Total time: ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9067087",
   "metadata": {},
   "source": [
    "### ğŸ¤” Reflection Question:\n",
    "**Why does endpoint deployment take so long?**\n",
    "```\n",
    "[Your answer: Think about virtual environment creation, dependency installation, container setup]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87b7ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ§ª LEVEL 3: Advanced Testing & Integration (30 min)\n",
    "\n",
    "**Goal:** Test endpoint and build robust API client\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Task 8: Get API Credentials\n",
    "\n",
    "**What you need to do:**\n",
    "1. Get Databricks workspace URL\n",
    "2. Get API token for authentication\n",
    "\n",
    "**ğŸ’¡ Security:** Never hardcode tokens! Always get them from secure context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Get API credentials\n",
    "\n",
    "# Hint:\n",
    "# API_ROOT = f\"https://{dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().value()}/\"\n",
    "# API_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)\n",
    "\n",
    "# Verify (don't print full token for security!)\n",
    "# print(f\"API Root: {API_ROOT}\")\n",
    "# print(f\"Token loaded: {API_TOKEN is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806d39d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› ï¸ Task 9: Build API Client Function\n",
    "\n",
    "**What you need to do:**\n",
    "Create a `score_model()` function that:\n",
    "1. Formats input data correctly (DataFrame or dict)\n",
    "2. Sends POST request to endpoint\n",
    "3. Handles authentication\n",
    "4. Returns predictions or raises error\n",
    "\n",
    "**ğŸ’¡ The function must handle two input formats:**\n",
    "- **Pandas DataFrame:** Convert to `dataframe_split` format\n",
    "- **Dict/Array:** Convert to TensorFlow Serving format\n",
    "\n",
    "**Structure:**\n",
    "```python\n",
    "def score_model(dataset):\n",
    "    # 1. Construct endpoint URL\n",
    "    # 2. Set headers (auth + content-type)\n",
    "    # 3. Format data based on type\n",
    "    # 4. Send POST request\n",
    "    # 5. Handle response\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b9e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Create helper function for TensorFlow format\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "    \"\"\"\n",
    "    Prepares input data in JSON format expected by TensorFlow Serving.\n",
    "    Converts data to nested dict under 'inputs' key.\n",
    "    \"\"\"\n",
    "    # Hint: Check if data is dict, convert values to lists\n",
    "    # If not dict, convert directly to list\n",
    "    # Return: {'inputs': {...}}\n",
    "    \n",
    "    pass  # Remove and write your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Create score_model function\n",
    "\n",
    "def score_model(dataset):\n",
    "    \"\"\"\n",
    "    Send prediction request to model serving endpoint.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Pandas DataFrame or dict with features\n",
    "        \n",
    "    Returns:\n",
    "        Predictions as JSON\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Construct endpoint URL\n",
    "    # Hint: url = f'{API_ROOT}/serving-endpoints/{MODEL_SERVING_ENDPOINT_NAME}/invocations'\n",
    "    \n",
    "    # Step 2: Set headers\n",
    "    # Hint: headers = {'Authorization': f'Bearer {API_TOKEN}', 'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Step 3: Format data based on type\n",
    "    # Hint: If DataFrame â†’ {'dataframe_split': dataset.to_dict(orient='split')}\n",
    "    #       Else â†’ create_tf_serving_json(dataset)\n",
    "    \n",
    "    # Step 4: Convert to JSON\n",
    "    # Hint: data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "    \n",
    "    # Step 5: Send POST request\n",
    "    # Hint: response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    \n",
    "    # Step 6: Handle response\n",
    "    # Hint: Check response.status_code, raise exception if not 200\n",
    "    \n",
    "    pass  # Remove and write your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc70c7",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- Function handles both DataFrames and dicts\n",
    "- Proper error handling for failed requests\n",
    "- Returns JSON response with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a1b40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª Task 10: Test API with Sample Data\n",
    "\n",
    "**What you need to do:**\n",
    "1. Load sample data (5 rows from feature table)\n",
    "2. Select only required columns\n",
    "3. Convert to pandas\n",
    "4. Call `score_model()` function\n",
    "5. Display predictions\n",
    "\n",
    "**Required columns:**\n",
    "- `avg_energy`, `std_sensor_A`, `std_sensor_B`, `std_sensor_C`, `std_sensor_D`, `std_sensor_E`, `std_sensor_F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ea6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Prepare test data\n",
    "\n",
    "# Step 1: Define columns list\n",
    "# columns = ['avg_energy', 'std_sensor_A', ...]\n",
    "\n",
    "# Step 2: Load sample data\n",
    "# Hint: dataset = spark.table('turbine_hourly_features').select(*columns).toPandas()[:5]\n",
    "\n",
    "# Step 3: Display data\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Call API and get predictions\n",
    "# Hint: predictions = score_model(dataset)\n",
    "#       print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78959d",
   "metadata": {},
   "source": [
    "### âœ… Success Criteria:\n",
    "- API call successful (status 200)\n",
    "- Predictions returned for all 5 rows\n",
    "- Predictions are numeric (0, 1, 2, ...)\n",
    "- Response time < 5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316d322",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Task 11: Compare Batch vs Real-Time Performance\n",
    "\n",
    "**What you need to do:**\n",
    "1. Measure API response time for 1 row\n",
    "2. Measure API response time for 100 rows\n",
    "3. Compare with batch UDF performance\n",
    "4. Analyze when to use each approach\n",
    "\n",
    "**ğŸ’¡ Use Python's `time` module to measure duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Test API with 1 row\n",
    "\n",
    "# import time\n",
    "# \n",
    "# single_row = dataset.iloc[:1]\n",
    "# \n",
    "# start = time.time()\n",
    "# prediction = score_model(single_row)\n",
    "# duration = time.time() - start\n",
    "# \n",
    "# print(f\"â±ï¸ API latency (1 row): {duration:.3f} seconds\")\n",
    "# print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca048f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Test API with 100 rows\n",
    "\n",
    "# large_dataset = spark.table('turbine_hourly_features').select(*columns).toPandas()[:100]\n",
    "# \n",
    "# start = time.time()\n",
    "# predictions = score_model(large_dataset)\n",
    "# duration = time.time() - start\n",
    "# \n",
    "# print(f\"â±ï¸ API latency (100 rows): {duration:.3f} seconds\")\n",
    "# print(f\"Throughput: {100/duration:.1f} predictions/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da011cb",
   "metadata": {},
   "source": [
    "### ğŸ¤” Reflection Questions:\n",
    "\n",
    "**1. How fast is the API for single predictions?**\n",
    "```\n",
    "[Your answer: Response time in seconds]\n",
    "```\n",
    "\n",
    "**2. How does throughput compare: API vs Batch UDF?**\n",
    "```\n",
    "[Your answer: Predictions per second for each method]\n",
    "```\n",
    "\n",
    "**3. When would you choose API over batch UDF?**\n",
    "```\n",
    "[Your answer: Consider latency, volume, use case]\n",
    "```\n",
    "\n",
    "**4. What happens if endpoint scales to zero and you send a request?**\n",
    "```\n",
    "[Your answer: Think about cold start time]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57146c49",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ BONUS Task: SQL Testing with ai_query() (Optional)\n",
    "\n",
    "**âš ï¸ Note:** `ai_query()` is NOT available in Free Edition, but we show it for learning purposes.\n",
    "\n",
    "**What it does:**\n",
    "- Call ML endpoints directly from SQL\n",
    "- Apply batch predictions without Python\n",
    "- Accessible to business analysts\n",
    "\n",
    "**Try this (will fail in Free Edition):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Try ai_query (will fail in Free Edition)\n",
    "\n",
    "%sql\n",
    "-- This demonstrates ai_query syntax (requires paid edition)\n",
    "-- SELECT ai_query(\n",
    "--     'e2eai_iot_turbine_prediction_endpoint',\n",
    "--     STRUCT(\n",
    "--         CAST(avg_energy AS DOUBLE) AS avg_energy, \n",
    "--         CAST(std_sensor_A AS DOUBLE) AS std_sensor_A, \n",
    "--         CAST(std_sensor_B AS DOUBLE) AS std_sensor_B, \n",
    "--         CAST(std_sensor_C AS DOUBLE) AS std_sensor_C, \n",
    "--         CAST(std_sensor_D AS DOUBLE) AS std_sensor_D, \n",
    "--         CAST(std_sensor_E AS DOUBLE) AS std_sensor_E,\n",
    "--         CAST(std_sensor_F AS DOUBLE) AS std_sensor_F\n",
    "--     ), \n",
    "--     returnType => 'FLOAT'\n",
    "-- ) AS prediction\n",
    "-- FROM turbine_hourly_features\n",
    "-- LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1bf6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You've completed the Model Deployment Challenge! ğŸ†\n",
    "\n",
    "### What You've Accomplished:\n",
    "\n",
    "âœ… **Batch Inference** - Spark UDF for large-scale predictions (Level 1)  \n",
    "âœ… **SQL Integration** - ML predictions in SQL queries  \n",
    "âœ… **REST API Deployment** - Production serving endpoint (Level 2)  \n",
    "âœ… **API Client** - Robust function for endpoint calls  \n",
    "âœ… **Performance Testing** - Compared batch vs real-time (Level 3)  \n",
    "âœ… **MLOps Best Practices** - Versioning, scale-to-zero, monitoring  \n",
    "\n",
    "### Deployment Summary:\n",
    "\n",
    "**Batch Inference (Spark UDF):**\n",
    "- âœ… UDF created and registered\n",
    "- âœ… Predictions saved in `turbine_hourly_predictions`\n",
    "- âœ… Available in SQL for analysts\n",
    "\n",
    "**Real-Time API:**\n",
    "- âœ… Serving endpoint deployed\n",
    "- âœ… Scale-to-zero enabled\n",
    "- âœ… API tested successfully\n",
    "- âœ… Response time: [Your result] seconds\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Next Steps in Production:\n",
    "\n",
    "**ğŸ“Š Monitoring:**\n",
    "- Track prediction accuracy over time\n",
    "- Monitor API latency and errors\n",
    "- Set up alerts for model drift\n",
    "\n",
    "**ğŸ”„ Model Updates:**\n",
    "- Retrain model with new data\n",
    "- Use A/B testing for new versions\n",
    "- Roll back if performance degrades\n",
    "\n",
    "**ğŸ” Security:**\n",
    "- Implement role-based access control\n",
    "- Audit endpoint usage\n",
    "- Encrypt predictions at rest\n",
    "\n",
    "**ğŸ’° Cost Optimization:**\n",
    "- Monitor endpoint costs\n",
    "- Adjust scale-to-zero timeout\n",
    "- Use batch inference for scheduled jobs\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’­ Final Reflection\n",
    "\n",
    "**1. Which deployment strategy is best for your use case?**\n",
    "```\n",
    "[Your answer: Batch UDF vs REST API - justify your choice]\n",
    "```\n",
    "\n",
    "**2. What was the most challenging part of deployment?**\n",
    "```\n",
    "[Your answer]\n",
    "```\n",
    "\n",
    "**3. How would you monitor this model in production?**\n",
    "```\n",
    "[Your answer: Think about metrics, alerts, dashboards]\n",
    "```\n",
    "\n",
    "**4. What improvements would you make for a real production system?**\n",
    "Options:\n",
    "- Load balancing for high traffic\n",
    "- Caching for frequently requested predictions\n",
    "- Automatic retraining pipeline\n",
    "- Feature store integration\n",
    "- A/B testing framework\n",
    "```\n",
    "[Your answer]\n",
    "```\n",
    "\n",
    "**5. Explain to a business stakeholder: Why did we deploy the model two ways?**\n",
    "```\n",
    "[Your answer: Focus on business value - when to use batch vs real-time]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒŸ Key Takeaways\n",
    "\n",
    "**MLOps is about more than just models:**\n",
    "- âœ… Lineage - Track what data created what model\n",
    "- âœ… Repeatability - Consistent environments and results\n",
    "- âœ… Consumption - Make predictions accessible\n",
    "- âœ… Performance - Monitor and improve over time\n",
    "\n",
    "**Two deployment patterns serve different needs:**\n",
    "- **Batch (UDF):** High volume, scheduled, cost-effective\n",
    "- **Real-Time (API):** Low latency, on-demand, flexible\n",
    "\n",
    "**Production readiness requires:**\n",
    "- Versioning and governance (Unity Catalog)\n",
    "- Error handling and retries\n",
    "- Monitoring and alerting\n",
    "- Cost optimization (scale-to-zero)\n",
    "- Security and access control\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“ You're now ready for production ML deployments!** ğŸš€\n",
    "\n",
    "**Want to see your endpoint in action?**\n",
    "Go to **Serving** in the Databricks UI â†’ Click your endpoint â†’ View usage statistics and code examples!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
