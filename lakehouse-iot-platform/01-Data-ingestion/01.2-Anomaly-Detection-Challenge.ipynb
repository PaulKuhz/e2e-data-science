{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ddf348a-37d2-4734-8781-190737551e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸ” Progressive Pipeline Challenge: From Data Quality to Medallion Architecture\n",
    "\n",
    "**Welcome to the advanced pipeline engineering challenge!** Now that you've seen how the basic pipeline works, it's time to extend it with professional data engineering patterns.\n",
    "\n",
    "## ðŸ“‹ Challenge Overview\n",
    "\n",
    "This challenge has **3 progressive levels** - choose your difficulty or complete all three to master pipeline engineering:\n",
    "\n",
    "| Level | Name | Difficulty | What You'll Build |\n",
    "|-------|------|------------|-------------------|\n",
    "| ðŸ¥‰ | **Data Quality Guardian** | Intermediate | Add data quality checks to existing tables |\n",
    "| ðŸ¥ˆ | **Anomaly Detective** | Advanced | Create new anomaly detection table |\n",
    "| ðŸ¥‡ | **Pipeline Architect** | Expert | Build complete Bronzeâ†’Silverâ†’Gold architecture |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– Background Story\n",
    "\n",
    "You're a Data Engineer at the wind turbine operations center. The basic pipeline is running, but your team lead says:\n",
    "\n",
    "> *\"The pipeline works, but we need better data quality, automated anomaly detection, and a proper medallion architecture. Can you enhance it?\"*\n",
    "\n",
    "**Your mission:** Extend the pipeline in `01.1-SDP-Wind-Turbine-SQL.ipynb` to make it production-ready!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Choose Your Challenge Level\n",
    "\n",
    "**New to pipelines?** â†’ Start with Level 1  \n",
    "**Comfortable with SQL?** â†’ Jump to Level 2  \n",
    "**Want the full experience?** â†’ Complete all 3 levels!\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ff991fa-159d-4c08-ba33-0f048a9fe7f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ¥‰ LEVEL 1: Data Quality Guardian\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "## ðŸ“š What You'll Learn\n",
    "\n",
    "- How to add data quality checks with `CONSTRAINT` and `EXPECT`\n",
    "- Different violation strategies: `DROP ROW`, `FAIL`, `QUARANTINE`\n",
    "- Why data quality matters in production pipelines\n",
    "\n",
    "## ðŸŽ¯ Your Mission\n",
    "\n",
    "The operations team reports that sometimes **bad sensor data** causes false alerts. Your task: Add quality checks to prevent invalid data from flowing through the pipeline.\n",
    "\n",
    "## ðŸ“ Task Instructions\n",
    "\n",
    "1. Open the pipeline notebook: `01-Data-ingestion/01.1-SDP-Wind-Turbine-SQL.ipynb`\n",
    "2. Find the `sensor_hourly` table definition\n",
    "3. Add **3-5 CONSTRAINT statements** to validate the data\n",
    "\n",
    "### Quality Rules to Implement\n",
    "\n",
    "Add constraints that check for:\n",
    "\n",
    "âœ… **Power values are realistic**\n",
    "- Power should be between 0 and 5000 kW\n",
    "- Action: DROP ROW if violated (bad sensor reading)\n",
    "\n",
    "âœ… **Vibration is within safe limits**\n",
    "- Vibration should be between 0 and 2\n",
    "- Action: FAIL if violated (pipeline should stop - critical issue!)\n",
    "\n",
    "âœ… **No null turbine IDs**\n",
    "- Turbine ID must not be null\n",
    "- Action: DROP ROW if violated\n",
    "\n",
    "âœ… **Temperature is reasonable**\n",
    "- Temperature should be between -30 and 50 degrees\n",
    "- Action: DROP ROW if violated\n",
    "\n",
    "âœ… **Your choice!** Think of another quality rule\n",
    "\n",
    "## ðŸ’¡ Code Hints\n",
    "\n",
    "```sql\n",
    "-- In 01.1-SDP-Wind-Turbine-SQL.ipynb, find this table:\n",
    "CREATE OR REFRESH LIVE TABLE sensor_hourly\n",
    "-- Add constraints like this AFTER the table name:\n",
    "(\n",
    "  CONSTRAINT valid_power EXPECT (avg_power > 0 AND avg_power < 5000) ON VIOLATION DROP ROW,\n",
    "  CONSTRAINT valid_vibration EXPECT (avg_vibration BETWEEN 0 AND 2) ON VIOLATION FAIL,\n",
    "  -- Add more constraints here...\n",
    ")\n",
    "AS SELECT ...\n",
    "```\n",
    "\n",
    "### ON VIOLATION Strategies\n",
    "\n",
    "- **DROP ROW:** Silently remove bad rows (for occasional bad readings)\n",
    "- **FAIL:** Stop the pipeline (for critical data issues)\n",
    "- **QUARANTINE:** Move to separate table for investigation\n",
    "\n",
    "## ðŸ“Š Success Criteria\n",
    "\n",
    "âœ… Added at least 3 CONSTRAINT statements  \n",
    "âœ… Used different ON VIOLATION strategies  \n",
    "âœ… Pipeline runs successfully \n",
    "\n",
    "**Level 1 Complete!** ðŸŽ‰ You've added production-grade data quality checks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8320a20-6177-4a8b-8a88-640f659d8134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ¥ˆ LEVEL 2: Anomaly Detective\n",
    "\n",
    "**Difficulty:** Advanced\n",
    "\n",
    "## ðŸ“š What You'll Learn\n",
    "\n",
    "- How to create new LIVE TABLEs in a pipeline\n",
    "- Window functions and statistical calculations\n",
    "- Z-score methodology for anomaly detection\n",
    "- Pipeline dependencies with `LIVE.table_name`\n",
    "\n",
    "## ðŸŽ¯ Your Mission\n",
    "\n",
    "Manual anomaly queries are too slow! Your manager wants **automated anomaly detection** that updates in real-time as new sensor data arrives.\n",
    "\n",
    "**Goal:** Create a new table `turbine_anomaly_scores` that automatically calculates anomaly scores for every turbine.\n",
    "\n",
    "## ðŸ“ Task Instructions\n",
    "\n",
    "1. Open `01-Data-ingestion/01.1-SDP-Wind-Turbine-SQL.ipynb`\n",
    "2. **Add a completely new table** at the end of the pipeline\n",
    "3. Calculate **Z-scores** for power and vibration sensors\n",
    "4. Classify turbines as NORMAL, WARNING, or CRITICAL\n",
    "\n",
    "## ðŸ’¡ Implementation Guide\n",
    "\n",
    "### Step 1: Create the Table Structure\n",
    "\n",
    "Add this to the end of your pipeline notebook:\n",
    "\n",
    "```sql\n",
    "CREATE OR REFRESH LIVE TABLE turbine_anomaly_scores\n",
    "COMMENT \"Real-time anomaly detection for turbines using Z-score method\"\n",
    "AS\n",
    "-- Your code here\n",
    "```\n",
    "\n",
    "### Step 2: Calculate Fleet Statistics\n",
    "\n",
    "Use a CTE (Common Table Expression) to calculate fleet-wide averages:\n",
    "\n",
    "```sql\n",
    "WITH fleet_stats AS (\n",
    "  SELECT \n",
    "    AVG(avg_power) as fleet_mean_power,\n",
    "    STDDEV(avg_power) as fleet_std_power,\n",
    "    AVG(avg_vibration) as fleet_mean_vibration,\n",
    "    STDDEV(avg_vibration) as fleet_std_vibration\n",
    "  FROM LIVE.sensor_hourly  -- Note: LIVE.table_name for pipeline dependencies!\n",
    ")\n",
    "```\n",
    "\n",
    "### Step 3: Calculate Z-Scores\n",
    "\n",
    "For each turbine, calculate how many standard deviations away from the mean:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  s.turbine_id,\n",
    "  s.window,\n",
    "  s.avg_power,\n",
    "  s.avg_vibration,\n",
    "  -- Z-score formula: (value - mean) / std_dev\n",
    "  (s.avg_power - f.fleet_mean_power) / NULLIF(f.fleet_std_power, 0) as power_z_score,\n",
    "  (s.avg_vibration - f.fleet_mean_vibration) / NULLIF(f.fleet_std_vibration, 0) as vibration_z_score\n",
    "FROM LIVE.sensor_hourly s\n",
    "CROSS JOIN fleet_stats f\n",
    "```\n",
    "\n",
    "### Step 4: Add Anomaly Classification\n",
    "\n",
    "Create a status field based on Z-scores:\n",
    "\n",
    "```sql\n",
    "CASE\n",
    "  WHEN ABS(power_z_score) > 3 OR ABS(vibration_z_score) > 3 THEN 'CRITICAL'\n",
    "  WHEN ABS(power_z_score) > 2 OR ABS(vibration_z_score) > 2 THEN 'WARNING'\n",
    "  ELSE 'NORMAL'\n",
    "END as anomaly_level\n",
    "```\n",
    "\n",
    "## ðŸŽ“ Bonus Challenges (Optional)\n",
    "\n",
    "### Bonus 1: Multi-Sensor Score\n",
    "Combine multiple sensors into one anomaly score:\n",
    "```sql\n",
    "(ABS(power_z_score) + ABS(vibration_z_score) + ABS(temp_z_score)) / 3 as composite_score\n",
    "```\n",
    "\n",
    "### Bonus 2: Business Impact\n",
    "Calculate estimated revenue loss for anomalous turbines:\n",
    "```sql\n",
    "CASE \n",
    "  WHEN avg_power < fleet_mean_power \n",
    "  THEN (fleet_mean_power - avg_power) * 0.05  -- $0.05 per kW\n",
    "  ELSE 0 \n",
    "END as estimated_hourly_revenue_loss\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## ðŸ“Š Success Criteria\n",
    "\n",
    "âœ… Created new `turbine_anomaly_scores` LIVE TABLE  \n",
    "âœ… Calculated Z-scores for at least 2 sensors  \n",
    "âœ… Classified turbines as NORMAL/WARNING/CRITICAL  \n",
    "âœ… Pipeline runs successfully with new table  \n",
    "\n",
    "**Level 2 Complete!** ðŸŽ‰ You've built automated anomaly detection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30058500-7e93-4d09-b558-8f2521e8baad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ¥‡ LEVEL 3: Pipeline Architect\n",
    "\n",
    "**Difficulty:** Expert\n",
    "\n",
    "## ðŸ“š What You'll Learn\n",
    "\n",
    "- Medallion Architecture (Bronze â†’ Silver â†’ Gold)\n",
    "- Layered data processing patterns\n",
    "- Incremental processing strategies\n",
    "- Business metrics calculation\n",
    "\n",
    "## ðŸŽ¯ Your Mission\n",
    "\n",
    "Your team lead is impressed! Now they want you to **refactor the entire pipeline** using the Medallion Architecture pattern - the industry standard for data lakes.\n",
    "\n",
    "**Goal:** Build a 3-layer architecture:\n",
    "- ðŸŸ¤ **Bronze:** Raw data with minimal cleaning\n",
    "- ðŸ¥ˆ **Silver:** Business logic and aggregations  \n",
    "- ðŸ¥‡ **Gold:** Analytics-ready tables with business metrics\n",
    "\n",
    "## ðŸ“ Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  BRONZE Layer (Raw + Validated)                        â”‚\n",
    "â”‚  - sensor_bronze_clean: Deduplicated raw sensor data   â”‚\n",
    "â”‚  - Quality: Structural validation only                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  SILVER Layer (Business Logic)                         â”‚\n",
    "â”‚  - sensor_silver_hourly: Hourly aggregations           â”‚\n",
    "â”‚  - Quality: Business rule validation                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  GOLD Layer (Analytics)                                â”‚\n",
    "â”‚  - turbine_gold_anomalies: Anomaly detection + scores  â”‚\n",
    "â”‚  - turbine_gold_kpis: Business metrics & revenue       â”‚\n",
    "â”‚  - Quality: Analytics validation                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ðŸ’¡ Implementation Guide\n",
    "\n",
    "### ðŸŸ¤ BRONZE LAYER: Clean Raw Data\n",
    "\n",
    "**Purpose:** Store raw data with minimal transformations, just remove duplicates and enforce structure.\n",
    "\n",
    "```sql\n",
    "-- Bronze Layer: Deduplicated sensor data\n",
    "CREATE OR REFRESH LIVE TABLE sensor_bronze_clean\n",
    "(\n",
    "  CONSTRAINT valid_timestamp EXPECT (timestamp IS NOT NULL) ON VIOLATION DROP ROW,\n",
    "  CONSTRAINT valid_turbine_id EXPECT (turbine_id IS NOT NULL) ON VIOLATION DROP ROW\n",
    ")\n",
    "COMMENT \"Bronze: Cleaned and deduplicated raw sensor readings\"\n",
    "AS \n",
    "SELECT DISTINCT\n",
    "  turbine_id,\n",
    "  timestamp,\n",
    "  AN,\n",
    "  AVALUES,\n",
    "  SPEED,\n",
    "  TORQUE,\n",
    "  FORCE\n",
    "FROM LIVE.sensor_bronze\n",
    "WHERE turbine_id IS NOT NULL;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ¥ˆ SILVER LAYER: Business Logic\n",
    "\n",
    "**Purpose:** Apply business transformations, aggregations, and enrichments.\n",
    "\n",
    "```sql\n",
    "CREATE OR REFRESH LIVE TABLE sensor_silver_hourly\n",
    "(\n",
    "  CONSTRAINT power_reasonable EXPECT (avg_power BETWEEN 0 AND 5000) ON VIOLATION DROP ROW,\n",
    "  CONSTRAINT vibration_safe EXPECT (avg_vibration BETWEEN 0 AND 2) ON VIOLATION FAIL\n",
    ")\n",
    "COMMENT \"Silver: Hourly sensor aggregations with business rules\"\n",
    "AS\n",
    "SELECT\n",
    "  turbine_id,\n",
    "  window(timestamp, \"1 hour\") as hour_window,\n",
    "  AVG(AVALUES) as avg_power,\n",
    "  MAX(AVALUES) as max_power,\n",
    "  STDDEV(AVALUES) as power_variability,\n",
    "  AVG(SPEED) as avg_vibration,\n",
    "  AVG(TORQUE) as avg_temperature,\n",
    "  COUNT(*) as reading_count\n",
    "FROM LIVE.sensor_bronze_clean\n",
    "GROUP BY turbine_id, window(timestamp, \"1 hour\");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ¥‡ GOLD LAYER: Analytics-Ready\n",
    "\n",
    "**Purpose:** Business-ready tables with KPIs, anomaly scores, and revenue metrics.\n",
    "\n",
    "```sql\n",
    "CREATE OR REFRESH LIVE TABLE turbine_gold_anomalies\n",
    "(\n",
    "  CONSTRAINT has_anomaly_score EXPECT (power_z_score IS NOT NULL),\n",
    "  CONSTRAINT valid_level EXPECT (anomaly_level IN ('NORMAL', 'WARNING', 'CRITICAL'))\n",
    ")\n",
    "COMMENT \"Gold: Real-time anomaly detection with business impact\"\n",
    "AS\n",
    "WITH fleet_stats AS (\n",
    "  SELECT \n",
    "    AVG(avg_power) as fleet_mean_power,\n",
    "    STDDEV(avg_power) as fleet_std_power,\n",
    "    AVG(avg_vibration) as fleet_mean_vibration,\n",
    "    STDDEV(avg_vibration) as fleet_std_vibration\n",
    "  FROM LIVE.sensor_silver_hourly\n",
    ")\n",
    "SELECT\n",
    "  s.turbine_id,\n",
    "  s.hour_window,\n",
    "  s.avg_power,\n",
    "  s.avg_vibration,\n",
    "  \n",
    "  -- Z-scores\n",
    "  (s.avg_power - f.fleet_mean_power) / NULLIF(f.fleet_std_power, 0) as power_z_score,\n",
    "  (s.avg_vibration - f.fleet_mean_vibration) / NULLIF(f.fleet_std_vibration, 0) as vibration_z_score,\n",
    "  \n",
    "  -- Anomaly classification\n",
    "  CASE\n",
    "    WHEN ABS((s.avg_power - f.fleet_mean_power) / NULLIF(f.fleet_std_power, 0)) > 3 THEN 'CRITICAL'\n",
    "    WHEN ABS((s.avg_power - f.fleet_mean_power) / NULLIF(f.fleet_std_power, 0)) > 2 THEN 'WARNING'\n",
    "    ELSE 'NORMAL'\n",
    "  END as anomaly_level,\n",
    "  \n",
    "  -- Business impact: Revenue loss estimation\n",
    "  CASE \n",
    "    WHEN s.avg_power < f.fleet_mean_power \n",
    "    THEN (f.fleet_mean_power - s.avg_power) * 0.05\n",
    "    ELSE 0 \n",
    "  END as estimated_hourly_revenue_loss\n",
    "  \n",
    "FROM LIVE.sensor_silver_hourly s\n",
    "CROSS JOIN fleet_stats f;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Success Criteria\n",
    "\n",
    "âœ… Created Bronze layer (cleaned data)  \n",
    "âœ… Created Silver layer (aggregations)  \n",
    "âœ… Created Gold layer (business metrics)  \n",
    "âœ… All tables have appropriate constraints  \n",
    "âœ… Can query business KPIs from Gold layer  \n",
    "\n",
    "**Level 3 Complete!** ðŸ† You've built a production-grade Medallion Architecture!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6200249373785441,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01.2-Anomaly-Detection-Challenge",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
